# 2.4.3 探索可能性

利用图 2 中的一些 Python 笔记本魔法，我们可以创建一个完全交互式的小程序来探索似然函数如何随着测量的不同结果而变化。

```
def likelihood_figure(weight):
    """Complicated figure to show likelihood for continuous case."""
    X = np.arange(0, 500)
    fig = make_subplots(
        rows=5, cols=2,
        column_widths=[0.6, 0.4],
        row_heights=[0.2, 0.2, 0.2, 0.2, 0.2],
        specs=[[{"type": "xy"}, {"type": "bar", "rowspan": 5}],
               [{"type": "xy"}, None],
               [{"type": "xy"}, None],
               [{"type": "xy"}, None],
               [{"type": "xy"}, None],
               ]
    )

    for index, category in enumerate(categories):
        fig.add_trace(
            go.Scatter(x=X, y=Gaussian(X, *pWC[index]), name=category),
            row=index+1, col=1
        )

    L = likelihood_given_weight(weight)
    fig.add_trace(go.Bar(x=L[::-1], y=categories[::-1], orientation="h",
                  name="Likelihood"), row=1, col=2)
    return fig
```

```
#| caption: Interactive plot showing the likelihood.
#| label: fig:interactive_likelihood
@interact(weight=(0, 500, 5))
def show_likelihood(weight=50):
    display(likelihood_figure(weight))
```

weight 滑动按钮

<figure><img src="../../.gitbook/assets/image (5).png" alt=""><figcaption><p>图2</p></figcaption></figure>

运行这个交互式小程序，可以深入了解似然函数的行为方式，以及随着权重测量的变化，ML 估计值在不同类别之间如何变化。我们实际上可以用一张便捷的图表来捕捉这些变化，即在 x 轴上绘制归一化似然函数与权重的关系，如图 3 所示。

```
def normalized(x):
    Lx = likelihood_given_weight(x)
    return Lx/np.sum(Lx)
X = np.arange(0.0,300)
Y = np.array([normalized(x) for x in X])
```

```
#| caption: Normalized likelihood for different weights and categories.
#| label: fig:normalized_likelihood
df = pd.DataFrame(data=Y, index=X, columns=categories, )
px.line(df, )
```

<figure><img src="../../.gitbook/assets/image (6).png" alt=""><figcaption><p>图3</p></figcaption></figure>

图中可以看到，随着权重的增加，最大似然类别依次从 `paper` 变为 `can` 再变为 `cardboard` ，然后 `scrap metal` 在大约 $$45g$$和 $$270g$$ 之间的较长时间内胜出，最终 `bottle` 成为 $$270g$$ 之上的 MLE。过渡点称为决策边界，表示我们的 ML 估计器在测量空间中改变其估计的位置。

注意：我们将在下面看到，我们在这里所做的规范化相当于假设我们对类别分布没有先验知识，这对于我们的垃圾分类示例来说当然是不正确的。
