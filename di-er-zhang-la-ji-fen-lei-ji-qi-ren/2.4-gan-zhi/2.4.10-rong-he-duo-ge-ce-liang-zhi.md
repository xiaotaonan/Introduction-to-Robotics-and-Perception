# 2.4.10  融合多个测量值

> 贝叶斯定理也可以轻松适应多种测量。

将贝叶斯定理应用于联合测量$$(z_1,z_2)$$可得出：

$$P(X|z_1,z_2) \infty L(X;z_1,z_2)P(X)$$（公式 3.34）

其中似然函数定义为：

$$L(X;z_1,z_2) \infty P(z_1,z_2|X)$$（公式 3.35）

通常，在给定状态变量$$X$$的情况下，传感器测量值是条件独立的。从数学上讲，如果满足$$X$$\
，则结果$$Z_1$$和$$Z_2$$是条件独立的：

$$P(Z_1,Z_2|X)=P()Z_1|X)P(Z_2|X)$$（公式3.36）

条件独立性通常发生在两个传感器都依赖于状态的相同方面时。在这种情况下，当状态未知时，关于$$Z_1$$的信息可能有助于判断$$Z_2$$的可能值；但一旦状态已知，了解$$Z_1$$的值将不会影响我们对$$Z_2$$的预期。

当$$Z_1$$和$$Z_2$$条件独立于$$X$$时，似然函数分解为一个乘积：

$$L(X;z_1,z_2) \infty L(X;z_1)L(X;z_2)$$（公式 3.37）

因此，贝叶斯定理就变成了：

$$P(X|z_1,z_2) \infty L(X;z_1)L(X;z_2)P(X)$$（公式 3.38）

换句话说，后验概率与先验概率加权的似然值的乘积成正比。该结果可推广至任意数量的传感器测量值，只要它们在变量 X 的给定值下条件独立即可。

需要注意的是，条件独立性仅在$$X$$的值已知时适用。除非传感器在统计上独立（即$$P(Z_1,Z_2)=P(Z_1)P(Z_2)）$$，否则如果$$X$$未知，则传感器测量值不独立。在公式$$19$$中，变量$$X$$始终出现在条件条后面，这是我们表达“给定一个已知类别”的方式。

作为本节的最后一个例子，基于上述广义贝叶斯定理，我们最终可以将三个测量结果的信息融合成该类别的后验概率。例如，给定权重 $$50g$$ 、电导率测量结果 `False` 以及检测器测量结果 `cardboard` ，我们得到如下似然函数：

```
likelihood = weight_50_factor * conductivity_false_factor * detected_cardboard_factor
pretty(likelihood)
```

| Category    |    Value    |
| ----------- | :---------: |
| cardboard   | 0.000386103 |
| paper       | 4.07079e-20 |
| can         | 6.02892e-14 |
| scrap metal | 0.000119776 |
| bottle      | 1.73517e-05 |

并且，在与先验相乘并进行归一化之后，得到以下后验：

```
posterior = gtsam.DiscreteDistribution(likelihood * category_prior)
pretty(posterior)
```

| Category    |    Value    |
| ----------- | :---------: |
| cardboard   |   0.756743  |
| paper       | 1.19678e-16 |
| can         | 1.47705e-10 |
| scrap metal |   0.234754  |
| bottle      |  0.00850212 |

我们看到 `cardboard` 是 MAP 估计值，概率为 76% ，但 `scrap metal` 也拥有相当大的概率（ 23% ）。请注意，仅从可能性来看，我们可能已经猜到纸板的可能性很高（实际上，这是 ML 估计值），但先验概率使它成为更有可能的结果（看看这个！）。

图 5 中的交互式小程序创建了一个函数来计算任何测量组合的后验，并允许您探索离散-连续测量空间中的后验。

```
def posterior(conductivity, detection, weight):
    """Calculate posterior for any measurement combination."""
    conductivity_factor = pCT.likelihood(conductivity)
    detector_factor = pDT.likelihood(detector_outcomes.index(detection))
    weight_factor = gtsam.DecisionTreeFactor(
        Category, likelihood_given_weight(weight))
    Px = gtsam.DiscreteDistribution(
        conductivity_factor* detector_factor * weight_factor * category_prior)
    return Px.pmf()
```

```
#| caption: Interactive plot showing the posterior.
#| label: fig:interactive_posterior
@interact(conductivity=[0,1], detection=detector_outcomes)
def show_posterior(conductivity=0, detection="paper"):
    X = np.arange(0.0, 300)
    Y = np.array([posterior(conductivity, detection, weight) for weight in X])

    # make use of pandas/plotly integration for pretty graph:
    df = pd.DataFrame(data=Y, index=X, columns=categories, )
    display(px.line(df))
```

conductivity...(0/1)

detetion...(bottle,cardboard,paper)

<figure><img src="../../.gitbook/assets/image (1) (1) (1) (1) (1).png" alt=""><figcaption><p>图5</p></figcaption></figure>
