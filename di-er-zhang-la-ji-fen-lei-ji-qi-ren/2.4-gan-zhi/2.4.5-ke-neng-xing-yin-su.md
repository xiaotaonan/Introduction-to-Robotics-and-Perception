# 2.4.5 可能性因素

> 我们可以用一个因子来表示未知状态的可能性。

本书中的所有感知算法都高度依赖于似然函数，现在我们引入一个特殊的数据结构，以便于在代码中表示它们。对于高斯测量模型，我们可以使用上面为重量传感器计算的似然函数来实例化一个 `DecisionTreeFactor` ：

```
weight_50_factor = gtsam.DecisionTreeFactor(
    Category, likelihood_given_weight(50))
pretty(weight_50_factor)
```

| Category    | Value       |
| ----------- | ----------- |
| cardboard   | 0.000443185 |
| paper       | 2.05595e-19 |
| can         | 1.82694e-12 |
| scrap metal | 0.00241971  |
| bottle      | 0.000913245 |

形式上，因子$$\phi(X)$$只是一个从结果$$x$$到实数的函数，因此，我们可以用它来表示给定测量值$$z$$时所有可能结果的似然值。当以这种方式使用时，我们将$$\phi$$称为似然因子，并通过以下方式明确表示对$$z$$的依赖性：

$$\phi(X;z)$$ （公式 2.21）

与似然函数$$L(X;z)$$类似。为了区分来自不同传感器的似然因子，我们使用下标，例如，我们上面推导的权重似然因子可以写成这样：

$$\phi_{\omega}(Category;Weight=50)$$（公式 2.22）

现在让我们为离散检测因子定义似然因子 $$\phi(Category;Detection)$$ 。在 GTSAM 中， `DiscreteConditional` 类实际上有一个方便的 `likelihood` 方法，我们可以通过该方法挑选出列。例如，对应于 `cardboard` 检测：

```
detector_outcomes = ["bottle", "cardboard", "paper"]
index = detector_outcomes.index("cardboard")  # 1 is the index for "cardboard"
detected_cardboard_factor = pDT.likelihood(index)
pretty(detected_cardboard_factor)
```

| Category    | Value |
| ----------- | :---: |
| cardboard   |  0.88 |
| paper       |  0.20 |
| can         |  0.33 |
| scrap metal |  0.33 |
| bottle      |  0.02 |

图 4 展示了一个小型交互式小程序，它允许我们检查每个可能的检测结果的似然因子。请注意，我们使用内置的 `index` 函数将检测结果转换为整数索引：

```
#| caption: The likelihood of observing a category given a detection.
#| label: fig:likelihood_given_detection
@interact(detection=detector_outcomes)
def show_likelihood(detection="bottle"):
    index = detector_outcomes.index(detection)
    L_index = [v for (k,v) in pDT.likelihood(index).enumerate()]
    display(px.bar(x=L_index, y=categories))
```

detecton ...(bottle,cardboard,paper)

<figure><img src="../../.gitbook/assets/image (7).png" alt=""><figcaption><p>图5</p></figcaption></figure>

然而，挑选出最有可能的类别只能让我们走这么远：我们不清楚如何融合多个传感器测量值，或者如何整合先验信息。事实上，我们可以做得更好……我们可以使用贝叶斯定理来实现这两个目标。我们将在下文中首先解释联合分布的概念，然后再进行阐述。
