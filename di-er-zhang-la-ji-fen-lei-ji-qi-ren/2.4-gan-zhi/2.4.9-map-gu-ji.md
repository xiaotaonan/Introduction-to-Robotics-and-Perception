# 2.4.9 MAP 估计

> 我们通过贝叶斯定理将似然值与先验值结合起来得到后验值。

现在，我们终于能够最优地计算出关于“隐藏”状态 X 的所有已知信息，即给定并观察到的传感器测量值$$z$$ 。在 GTSAM 中，我们只需将似然因子 $$\phi(X;z)$$与未知变量 $$X$$ 的先验值 $$P(X)$$ 结合起来即可。这立即得出了所有类别 `detector_outcomes` 的概率分布。

变量$$X$$的最大后验或 MAP 估计$$x_{MAP}^{*}$$是最大化后验$$P(X|z)$$的值，即：

$$x_{MAP}^{*}=arg \mathop{max} \limits _{x}P(x|z)=arg \mathop{max} \limits _{x} L(x;z)P(X)$$ （公式 2.33）

例如，假设电导率传感器测量到 `False` ，那么我们对 `Category` 的了解又是什么呢？代码会创建一个因子，将其与先验值相乘，然后将结果显示为一个（漂亮的）表格：

```
conductivity_false_factor = pCT.likelihood(0)
pretty(conductivity_false_factor)
```

| Category    | Value |
| ----------- | :---: |
| cardboard   |  0.99 |
| paper       |  0.99 |
| can         |  0.10 |
| scrap metal |  0.15 |
| bottle      |  0.95 |

```
unnormalized_posterior = conductivity_false_factor * category_prior
print(type(unnormalized_posterior))
print(sum(p for _, p in unnormalized_posterior.enumerate()))
pretty(unnormalized_posterior)
```

```
<class 'gtsam.gtsam.DecisionTreeFactor'>
0.5975
```

| Category    |  Value |
| ----------- | :----: |
| cardboard   |  0.198 |
| paper       |  0.297 |
| can         |  0.025 |
| scrap metal |  0.03  |
| bottle      | 0.0475 |

上面，我们还打印出了类型 (a `DecisionTreeFactor` ) 以及乘积的和，但和并不等于 1.0！事实上，一个因子与一个条件的乘积会产生另一个因子，即非归一化的后验，即贝叶斯定理第二种形式的右边。

请注意，鉴于我们先前的知识和 `False` 电导率测量值，我们无需进行归一化即可看到 MAP 类别为 `paper` 。但是，如果能看到实际概率为 `detector_outcomes` 就更好了。这可以通过归一化来实现，在 GTSAM 中，最简单的方法是将因子转换为 `DiscreteDistribution` ，如下所示：

```
posterior = gtsam.DiscreteDistribution(unnormalized_posterior)
print(type(posterior))
assert sum(p for _, p in posterior.enumerate()) == 1.0
pretty(posterior)
```

```
<class 'gtsam.gtsam.DiscreteDistribution'>
```

| Category    |   Value   |
| ----------- | :-------: |
| cardboard   |  0.331381 |
| paper       |  0.497071 |
| can         |  0.041841 |
| scrap metal | 0.0502092 |
| bottle      | 0.0794979 |

现在我们可以更容易地理解相对后验概率了。 `paper` 类别已经是先验概率最高的类别，为 30% ，而负电导率的测量结果进一步增强了我们对这一结果的信心，几乎达到了 50% 。

相反，如果我们进行的是正电导率测量，我们就会得到非常不同的结果：

```
Cat_given_Con1 = gtsam.DiscreteDistribution(pCT.likelihood(1) * category_prior)
assert sum(p for _, p in Cat_given_Con1.enumerate()) == 1.0
pretty(Cat_given_Con1)
```

| Category    |    Value   |
| ----------- | :--------: |
| cardboard   | 0.00496894 |
| paper       | 0.00745342 |
| can         |  0.559006  |
| scrap metal |   0.42236  |
| bottle      | 0.00621118 |

现在， `can` 类别是 MAP 估计，而 `cardboard` 的后验概率几乎是 0% 。原因是，在电导率为正的情况下， `paper` 的可能性非常低（检查一下！）。
