# 1.2.3 学习

> 通过学习数据，我们可以让机器人变得更智能。

对于许多应用而言，我们不可能为机器人编写针对所有可能出现情况的程序。在某些情况下，这是因为可能发生的情况数量任意多。在其他应用中，情况可能过于复杂，难以精确建模。还有一些情况下，我们根本无法预先知道机器人可能面临的所有情况。

在这些情况下，机器学习可以用来适应未知或不断变化的情况，或者随着时间的推移提高机器人的性能。本书将探讨三种主要的机器学习类型：简单的统计分析、强化学习和基于神经网络的学习。

对于具有少量未知参数的系统，通常使用统计方法估计这些参数的值就足够了。例如，如果垃圾分类机器人不知道到达分类器的不同类别垃圾的先验概率，则可以通过随时间观察系统来估计这些概率。如果机器人操纵一个未知物体，它可以通过传感器的测量值来估计该物体的质量。如果传感器存在噪声，但其相关噪声模型的参数未知，我们可以通过校准来估计这些参数，这也是一种学习。

对于需要长期运行的系统，通常可以通过经验来提升性能。强化学习是一种流行的方法。简而言之，导致成功结果的行为会得到奖励，从而强化成功的行为。在第三章中，我们将介绍用于吸尘器机器人的强化学习，包括一种流行的变体——Q 学习。Q 学习并非明确地学习哪些动作最有效，而是学习一个函数，该函数可以模拟在特定状态下应用动作的长期奖励。然后，我们可以将该函数转化为策略，即在给定状态下如何行动的处方。

对于涉及大型数据集的问题，基于神经网络的方法，尤其是深度学习，通常能够提供有效的解决方案。神经网络可以被视为函数逼近器。对于物体识别的计算机视觉问题，近似函数以图像作为输入，输出物体的分类。许多其他视觉任务，例如图像分割、场景深度和场景运动，都可以使用现代神经网络来解决。

神经网络由简单的处理节点构成，这些节点通过加权边相互连接。权重有效地决定了网络的计算量，因此神经网络的关键问题在于权重的学习。我们将在第 5 章介绍神经网络，然后介绍深度神经网络，用于解决图像处理和计算机视觉问题。之后，在第 6 章中，我们将深度学习与强化学习相结合，形成了一种称为深度强化学习（DRL）的方法。最后，在第 7 章中，我们将使用相同的可微优化方法来建模环境，并讨论神经辐射场（NeRF）及其在自主飞行中的应用。
