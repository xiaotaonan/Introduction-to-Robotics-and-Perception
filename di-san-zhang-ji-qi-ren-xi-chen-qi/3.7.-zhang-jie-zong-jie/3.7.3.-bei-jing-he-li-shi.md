# 3.7.3. 背景和历史

马尔可夫链可以追溯到 - 你猜对了 - 安德烈·马尔可夫 （[Andrey Markov](https://en.wikipedia.org/wiki/Andrey_Markov)），他使用它们来研究语言的统计数据等。事实上，证明了这个概念的重要性和普遍性，任何有限上下文的大型语言模型都可以被看作是一个马尔可夫链 - 诚然，它有一个相当大的状态空间。

在这本书中，我们使用因子图作为概率推理的组织结构。在后面的章节中，我们将把它们的使用扩展到连续变量，并将看到因子图恰当地描述了机器人技术中出现的大型非线性最小二乘问题的独立性假设和稀疏性质。但它们的用处远不止于此：它们是我们用作构建块的稀疏线性求解器的核心;它们清楚地显示了过滤和增量推理的性质;它们自然而然地导致了分布式和/或并行版本的机器人技术。更深入地了解因子图，包括一些历史笔记及其在机器人技术中的应用，可以在 thereview 论文 \[ [Dellaert 和 Kaess， 2017](https://www.roboticsbook.org/bibliography.html#id13)] 和 \[ [Dellaert， 2021](https://www.roboticsbook.org/bibliography.html#id14)] 中找到。

隐马尔可夫模型 （HMM） 于 1966 年由 Baum 和 Petrie \[ [1966](https://www.roboticsbook.org/bibliography.html#id5)] 提出，当它们被 IMB 应用于语音识别工作时真正取得突破 \[[Jelinek et al.， 1975](https://www.roboticsbook.org/bibliography.html#id33)]。我们为 HMM 引入的动态规划算法实际上是线性链结构因子图的特例。在 HMM 文献中，它们分别被称为 Viterbi 和 Forward-Backward 算法。然而，因为在每一步中，都会从最大化中消除一个变量，所以 max-product 和 sum-product 算法实际上是消除算法的实例（再次参见 Dellaert 和 Kaess \[ [2017 ](https://www.roboticsbook.org/bibliography.html#id13)的论文]），它适用于任意因子图，尽管不一定是时间上的$$O(n)$$。

最优性原则由 Bellman 在 1960 年的[ IEEETransactions on Automatic Control](https://www.rand.org/content/dam/rand/pubs/papers/2008/P1416.pdf)\[ [Bellman 和 Kalaba， 1960](https://www.roboticsbook.org/bibliography.html#id7)] 中陈述。马尔可夫决策过程强化学习最受尊敬的当代来源之一是 [Sutton 和 Barto 的书](http://incompleteideas.net/book/the-book-2nd.html) \[[ Sutton and Barto， 2018](https://www.roboticsbook.org/bibliography.html#id59)]，该书最近更新了第二版。Q-learning 可以追溯到 [Chris Watkins 的博士论文](https://www.cs.rhul.ac.uk/~chrisw/thesis.html) \[ [Watkins， 1989](https://www.roboticsbook.org/bibliography.html#id62)]。Pearl 的开创性著作 \[ [Pearl， 1988](https://www.roboticsbook.org/bibliography.html#id49)] 向人工智能界介绍了用于概率推理的通用贝叶斯网。Koller 和 Friedman \[ [2009](https://www.roboticsbook.org/bibliography.html#id35)] 在书中提供了用于概率推理的图形模型的现代综合处理。
